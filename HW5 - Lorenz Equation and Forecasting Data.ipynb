{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "811f1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Github link: https://github.com/sreksoz/Intro-to-Machine-Learning/tree/HW-5--Lorenz-Equation-and-Forecasting-Data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from scipy import integrate\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e907dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 15)\n",
    "        self.fc2 = nn.Linear(15, 6)\n",
    "        self.fc3 = nn.Linear(6, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0e2a84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model instance\n",
    "model = Net()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Define hyperparameters\n",
    "dt = 0.01\n",
    "T = 8\n",
    "t = np.arange(0,T+dt,dt)\n",
    "beta = 8/3\n",
    "sigma = 10\n",
    "# Given rho values to train and test\n",
    "rho_values_train = [10, 28, 40]\n",
    "rho_values_test = [17, 35]\n",
    "\n",
    "\n",
    "# Define the NN input and output\n",
    "nn_input = np.zeros((100*(len(t)-1),3))\n",
    "nn_output = np.zeros_like(nn_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3227103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss=274.7623\n",
      "Epoch 2, loss=199.3614\n",
      "Epoch 3, loss=265.0704\n",
      "Epoch 4, loss=617.9752\n",
      "Epoch 5, loss=280.3966\n",
      "Epoch 6, loss=276.1551\n",
      "Epoch 7, loss=272.1067\n",
      "Epoch 8, loss=267.6044\n",
      "Epoch 9, loss=260.7444\n",
      "Epoch 10, loss=251.4229\n",
      "Epoch 11, loss=239.3160\n",
      "Epoch 12, loss=228.1230\n",
      "Epoch 13, loss=217.1938\n",
      "Epoch 14, loss=202.7013\n",
      "Epoch 15, loss=168.8647\n",
      "Epoch 16, loss=293.1321\n",
      "Epoch 17, loss=182.2799\n",
      "Epoch 18, loss=175.5872\n",
      "Epoch 19, loss=167.6380\n",
      "Epoch 20, loss=160.9444\n",
      "Epoch 21, loss=154.7194\n",
      "Epoch 22, loss=148.9911\n",
      "Epoch 23, loss=143.7739\n",
      "Epoch 24, loss=139.0699\n",
      "Epoch 25, loss=134.8714\n",
      "Epoch 26, loss=131.1620\n",
      "Epoch 27, loss=127.9189\n",
      "Epoch 28, loss=125.1142\n",
      "Epoch 29, loss=122.7162\n",
      "Epoch 30, loss=120.6909\n"
     ]
    }
   ],
   "source": [
    "# Create a list for input and output for the neural network (after data preparation)\n",
    "nn_input_final = []\n",
    "nn_output_final = []\n",
    "\n",
    "# Data preparation\n",
    "for rho in rho_values_train:\n",
    "    \n",
    "    # Define the Lorenz equation\n",
    "    def lorenz_deriv(x_y_z, t0, sigma=sigma, beta=beta, rho=rho):\n",
    "        x, y, z = x_y_z\n",
    "        return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]\n",
    "\n",
    "    np.random.seed(123)\n",
    "    x0 = -15 + 30 * np.random.random((100, 3))\n",
    "\n",
    "    x_t = np.asarray([integrate.odeint(lorenz_deriv, x0_j, t)\n",
    "                      for x0_j in x0])\n",
    "    \n",
    "    for j in range(100):\n",
    "        nn_input[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,:-1,:]\n",
    "        nn_output[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,1:,:]\n",
    "        \n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    nn_input_tensor = torch.from_numpy(nn_input).float()\n",
    "    nn_output_tensor = torch.from_numpy(nn_output).float()\n",
    "    \n",
    "    # Appending the tensors to a list\n",
    "    nn_input_final.append(nn_input_tensor)\n",
    "    nn_output_final.append(nn_output_tensor)\n",
    "    \n",
    "\n",
    "# Concatenate the neural network input and outputs from each rho values\n",
    "nn_in = torch.cat(nn_input_final)\n",
    "nn_out = torch.cat(nn_output_final)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(30):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(nn_in)\n",
    "    loss = criterion(outputs, nn_out)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, loss={loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee5f694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least squares error of test data: 95.89716339111328\n"
     ]
    }
   ],
   "source": [
    "# Create a list for input and output for the neural network (for testing)\n",
    "nn_input_test = []\n",
    "nn_output_test = []\n",
    "\n",
    "# Test the network with given test rho values\n",
    "for rho in rho_values_test:\n",
    "    \n",
    "    # Define the Lorenz equation\n",
    "    def lorenz_deriv(x_y_z, t0, sigma=sigma, beta=beta, rho=rho):\n",
    "        x, y, z = x_y_z\n",
    "        return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]\n",
    "\n",
    "    np.random.seed(123)\n",
    "    x0 = -15 + 30 * np.random.random((100, 3))\n",
    "\n",
    "    x_t = np.asarray([integrate.odeint(lorenz_deriv, x0_j, t)\n",
    "                      for x0_j in x0])\n",
    "    \n",
    "    for j in range(100):\n",
    "        nn_input[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,:-1,:]\n",
    "        nn_output[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,1:,:]\n",
    "        \n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    nn_input_tensor = torch.from_numpy(nn_input).float()\n",
    "    nn_output_tensor = torch.from_numpy(nn_output).float()\n",
    "    \n",
    "     # Appending the tensors to a list\n",
    "    nn_input_test.append(nn_input_tensor)\n",
    "    nn_output_test.append(nn_output_tensor)\n",
    "\n",
    "# Concatenate the neural network input and outputs from each rho values\n",
    "nn_in = torch.cat(nn_input_test)\n",
    "nn_out = torch.cat(nn_output_test)\n",
    "    \n",
    "# Test the network\n",
    "with torch.no_grad():\n",
    "    outputs = model(nn_in)\n",
    "    compute_mse = criterion(outputs, nn_out)\n",
    "\n",
    "    print('Least squares error of test data: {}'.format(compute_mse.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe56db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LSTM neural network architecture\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_size=3, hidden_size=15, num_layers=1, output_size=3):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers, self.hidden_size)\n",
    "        \n",
    "        # LSTM layer\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Fully connected layer\n",
    "        out = self.fc(out[:, :])\n",
    "        \n",
    "        return out\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34881ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss=295.5326\n",
      "Epoch 2, loss=288.6763\n",
      "Epoch 3, loss=282.2330\n",
      "Epoch 4, loss=272.1898\n",
      "Epoch 5, loss=254.3024\n",
      "Epoch 6, loss=235.2149\n",
      "Epoch 7, loss=213.6164\n",
      "Epoch 8, loss=190.4366\n",
      "Epoch 9, loss=167.3828\n",
      "Epoch 10, loss=145.9868\n",
      "Epoch 11, loss=128.4299\n",
      "Epoch 12, loss=115.1093\n",
      "Epoch 13, loss=106.6399\n",
      "Epoch 14, loss=102.1929\n",
      "Epoch 15, loss=101.4685\n",
      "Epoch 16, loss=94.1753\n",
      "Epoch 17, loss=108.5016\n",
      "Epoch 18, loss=108.4572\n",
      "Epoch 19, loss=104.8777\n",
      "Epoch 20, loss=110.0657\n",
      "Epoch 21, loss=86.2611\n",
      "Epoch 22, loss=84.1831\n",
      "Epoch 23, loss=82.5908\n",
      "Epoch 24, loss=82.7229\n",
      "Epoch 25, loss=75.6549\n",
      "Epoch 26, loss=75.8235\n",
      "Epoch 27, loss=70.1476\n",
      "Epoch 28, loss=68.6971\n",
      "Epoch 29, loss=66.0172\n",
      "Epoch 30, loss=62.9020\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the model used, which is LSTM\n",
    "model = LSTMNet().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Create a list for input and output for the neural network (after data preparation)\n",
    "nn_input_final = []\n",
    "nn_output_final = []\n",
    "\n",
    "# Define the NN input and output\n",
    "nn_input = np.zeros((100*(len(t)-1),3))\n",
    "nn_output = np.zeros_like(nn_input)\n",
    "\n",
    "# Data preparation\n",
    "for rho in rho_values_train:\n",
    "    \n",
    "    # Define the Lorenz equation\n",
    "    def lorenz_deriv(x_y_z, t0, sigma=sigma, beta=beta, rho=rho):\n",
    "        x, y, z = x_y_z\n",
    "        return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]\n",
    "\n",
    "    np.random.seed(123)\n",
    "    x0 = -15 + 30 * np.random.random((100, 3))\n",
    "\n",
    "    x_t = np.asarray([integrate.odeint(lorenz_deriv, x0_j, t)\n",
    "                      for x0_j in x0])\n",
    "    \n",
    "    for j in range(100):\n",
    "        nn_input[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,:-1,:]\n",
    "        nn_output[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,1:,:]\n",
    "        \n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    nn_input_tensor = torch.from_numpy(nn_input).float()\n",
    "    nn_output_tensor = torch.from_numpy(nn_output).float()\n",
    "    \n",
    "    # Appending the tensors to a list\n",
    "    nn_input_final.append(nn_input_tensor)\n",
    "    nn_output_final.append(nn_output_tensor)\n",
    "    \n",
    "\n",
    "# Concatenate the neural network input and outputs from each rho values\n",
    "nn_in = torch.cat(nn_input_final)\n",
    "nn_out = torch.cat(nn_output_final)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(30):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(nn_in)\n",
    "    loss = criterion(outputs, nn_out)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, loss={loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "231cfb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least squares error of test data: 50.31068801879883\n"
     ]
    }
   ],
   "source": [
    "# Create a list for input and output for the neural network (for testing)\n",
    "nn_input_test = []\n",
    "nn_output_test = []\n",
    "\n",
    "# Test the network with given test rho values\n",
    "for rho in rho_values_test:\n",
    "    \n",
    "    # Define the Lorenz equation\n",
    "    def lorenz_deriv(x_y_z, t0, sigma=sigma, beta=beta, rho=rho):\n",
    "        x, y, z = x_y_z\n",
    "        return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]\n",
    "\n",
    "    np.random.seed(123)\n",
    "    x0 = -15 + 30 * np.random.random((100, 3))\n",
    "\n",
    "    x_t = np.asarray([integrate.odeint(lorenz_deriv, x0_j, t)\n",
    "                      for x0_j in x0])\n",
    "    \n",
    "    for j in range(100):\n",
    "        nn_input[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,:-1,:]\n",
    "        nn_output[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,1:,:]\n",
    "        \n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    nn_input_tensor = torch.from_numpy(nn_input).float()\n",
    "    nn_output_tensor = torch.from_numpy(nn_output).float()\n",
    "    \n",
    "     # Appending the tensors to a list\n",
    "    nn_input_test.append(nn_input_tensor)\n",
    "    nn_output_test.append(nn_output_tensor)\n",
    "\n",
    "# Concatenate the neural network input and outputs from each rho values\n",
    "nn_in = torch.cat(nn_input_test)\n",
    "nn_out = torch.cat(nn_output_test)\n",
    "    \n",
    "# Test the network\n",
    "with torch.no_grad():\n",
    "    outputs = model(nn_in)\n",
    "    compute_mse = criterion(outputs, nn_out)\n",
    "\n",
    "    print('Least squares error of test data: {}'.format(compute_mse.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "523d7930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an RNN neural network architecture\n",
    "class RNNNet(nn.Module):\n",
    "    def __init__(self, input_size=3, hidden_size=15, num_layers=1, output_size=3):\n",
    "        super(RNNNet, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, self.hidden_size)\n",
    "        \n",
    "        # RNN layer\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        out = self.fc(out[:, :])  # Use the last output timestep\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9de355bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss=292.3287\n",
      "Epoch 2, loss=255.3023\n",
      "Epoch 3, loss=210.5301\n",
      "Epoch 4, loss=160.9973\n",
      "Epoch 5, loss=122.4227\n",
      "Epoch 6, loss=105.1868\n",
      "Epoch 7, loss=107.8777\n",
      "Epoch 8, loss=107.1276\n",
      "Epoch 9, loss=118.7423\n",
      "Epoch 10, loss=103.8654\n",
      "Epoch 11, loss=106.2003\n",
      "Epoch 12, loss=98.0878\n",
      "Epoch 13, loss=96.2881\n",
      "Epoch 14, loss=94.4343\n",
      "Epoch 15, loss=89.5607\n",
      "Epoch 16, loss=93.0507\n",
      "Epoch 17, loss=93.5552\n",
      "Epoch 18, loss=91.8467\n",
      "Epoch 19, loss=89.3242\n",
      "Epoch 20, loss=86.3346\n",
      "Epoch 21, loss=82.3205\n",
      "Epoch 22, loss=77.5896\n",
      "Epoch 23, loss=74.4349\n",
      "Epoch 24, loss=73.6426\n",
      "Epoch 25, loss=73.7057\n",
      "Epoch 26, loss=73.3200\n",
      "Epoch 27, loss=70.8493\n",
      "Epoch 28, loss=68.0691\n",
      "Epoch 29, loss=64.1548\n",
      "Epoch 30, loss=65.5668\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the model used, which is LSTM\n",
    "model = RNNNet().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Create a list for input and output for the neural network (after data preparation)\n",
    "nn_input_final = []\n",
    "nn_output_final = []\n",
    "\n",
    "# Define the NN input and output\n",
    "nn_input = np.zeros((100*(len(t)-1),3))\n",
    "nn_output = np.zeros_like(nn_input)\n",
    "\n",
    "# Data preparation\n",
    "for rho in rho_values_train:\n",
    "    \n",
    "    # Define the Lorenz equation\n",
    "    def lorenz_deriv(x_y_z, t0, sigma=sigma, beta=beta, rho=rho):\n",
    "        x, y, z = x_y_z\n",
    "        return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]\n",
    "\n",
    "    np.random.seed(123)\n",
    "    x0 = -15 + 30 * np.random.random((100, 3))\n",
    "\n",
    "    x_t = np.asarray([integrate.odeint(lorenz_deriv, x0_j, t)\n",
    "                      for x0_j in x0])\n",
    "    \n",
    "    for j in range(100):\n",
    "        nn_input[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,:-1,:]\n",
    "        nn_output[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,1:,:]\n",
    "        \n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    nn_input_tensor = torch.from_numpy(nn_input).float()\n",
    "    nn_output_tensor = torch.from_numpy(nn_output).float()\n",
    "    \n",
    "    # Appending the tensors to a list\n",
    "    nn_input_final.append(nn_input_tensor)\n",
    "    nn_output_final.append(nn_output_tensor)\n",
    "    \n",
    "\n",
    "# Concatenate the neural network input and outputs from each rho values\n",
    "nn_in = torch.cat(nn_input_final)\n",
    "nn_out = torch.cat(nn_output_final)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(30):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(nn_in)\n",
    "    loss = criterion(outputs, nn_out)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, loss={loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edce3baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least squares error of test data: 50.16377258300781\n"
     ]
    }
   ],
   "source": [
    "# Create a list for input and output for the neural network (for testing)\n",
    "nn_input_test = []\n",
    "nn_output_test = []\n",
    "\n",
    "# Test the network with given test rho values\n",
    "for rho in rho_values_test:\n",
    "    \n",
    "    # Define the Lorenz equation\n",
    "    def lorenz_deriv(x_y_z, t0, sigma=sigma, beta=beta, rho=rho):\n",
    "        x, y, z = x_y_z\n",
    "        return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]\n",
    "\n",
    "    np.random.seed(123)\n",
    "    x0 = -15 + 30 * np.random.random((100, 3))\n",
    "\n",
    "    x_t = np.asarray([integrate.odeint(lorenz_deriv, x0_j, t)\n",
    "                      for x0_j in x0])\n",
    "    \n",
    "    for j in range(100):\n",
    "        nn_input[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,:-1,:]\n",
    "        nn_output[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,1:,:]\n",
    "        \n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    nn_input_tensor = torch.from_numpy(nn_input).float()\n",
    "    nn_output_tensor = torch.from_numpy(nn_output).float()\n",
    "    \n",
    "     # Appending the tensors to a list\n",
    "    nn_input_test.append(nn_input_tensor)\n",
    "    nn_output_test.append(nn_output_tensor)\n",
    "\n",
    "# Concatenate the neural network input and outputs from each rho values\n",
    "nn_in = torch.cat(nn_input_test)\n",
    "nn_out = torch.cat(nn_output_test)\n",
    "    \n",
    "# Test the network\n",
    "with torch.no_grad():\n",
    "    outputs = model(nn_in)\n",
    "    compute_mse = criterion(outputs, nn_out)\n",
    "\n",
    "    print('Least squares error of test data: {}'.format(compute_mse.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd6c891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Echo States Network architecture\n",
    "class ESN(nn.Module):\n",
    "    def __init__(self, input_size=3, reservoir_size=100, output_size=3):\n",
    "        super(ESN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Reservoir layer\n",
    "        self.reservoir = nn.Linear(input_size + reservoir_size, reservoir_size)\n",
    "        \n",
    "        # Output layer\n",
    "        self.output = nn.Linear(reservoir_size, output_size)\n",
    "\n",
    "    def forward(self, x, reservoir_state):\n",
    "        # Concatenate input with reservoir state\n",
    "        combined_input = torch.cat([x, reservoir_state], dim=1)\n",
    "        \n",
    "        # Reservoir layer\n",
    "        reservoir_output = torch.tanh(self.reservoir(combined_input))\n",
    "        \n",
    "        # Output layer\n",
    "        output = self.output(reservoir_output)\n",
    "        \n",
    "        return output, reservoir_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c7738c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss=300.5471\n",
      "Epoch 2, loss=180.8709\n",
      "Epoch 3, loss=91.5154\n",
      "Epoch 4, loss=123.4013\n",
      "Epoch 5, loss=155.3483\n",
      "Epoch 6, loss=77.4563\n",
      "Epoch 7, loss=70.3367\n",
      "Epoch 8, loss=62.7786\n",
      "Epoch 9, loss=62.4004\n",
      "Epoch 10, loss=64.0828\n",
      "Epoch 11, loss=62.2120\n",
      "Epoch 12, loss=62.3209\n",
      "Epoch 13, loss=59.2354\n",
      "Epoch 14, loss=58.2525\n",
      "Epoch 15, loss=55.6917\n",
      "Epoch 16, loss=53.9776\n",
      "Epoch 17, loss=52.9975\n",
      "Epoch 18, loss=51.8251\n",
      "Epoch 19, loss=52.0794\n",
      "Epoch 20, loss=50.7887\n",
      "Epoch 21, loss=49.1469\n",
      "Epoch 22, loss=48.3943\n",
      "Epoch 23, loss=48.1675\n",
      "Epoch 24, loss=47.9274\n",
      "Epoch 25, loss=47.4216\n",
      "Epoch 26, loss=46.8212\n",
      "Epoch 27, loss=46.4049\n",
      "Epoch 28, loss=45.8008\n",
      "Epoch 29, loss=45.0182\n",
      "Epoch 30, loss=44.3235\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the model used, which is LSTM\n",
    "model = ESN(input_size=3, reservoir_size=100, output_size=3).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Create a list for input and output for the neural network (after data preparation)\n",
    "nn_input_final = []\n",
    "nn_output_final = []\n",
    "\n",
    "# Define the NN input and output\n",
    "nn_input = np.zeros((100*(len(t)-1),3))\n",
    "nn_output = np.zeros_like(nn_input)\n",
    "\n",
    "# Data preparation\n",
    "for rho in rho_values_train:\n",
    "    \n",
    "    # Define the Lorenz equation\n",
    "    def lorenz_deriv(x_y_z, t0, sigma=sigma, beta=beta, rho=rho):\n",
    "        x, y, z = x_y_z\n",
    "        return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]\n",
    "\n",
    "    np.random.seed(123)\n",
    "    x0 = -15 + 30 * np.random.random((100, 3))\n",
    "\n",
    "    x_t = np.asarray([integrate.odeint(lorenz_deriv, x0_j, t)\n",
    "                      for x0_j in x0])\n",
    "    \n",
    "    for j in range(100):\n",
    "        nn_input[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,:-1,:]\n",
    "        nn_output[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,1:,:]\n",
    "        \n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    nn_input_tensor = torch.from_numpy(nn_input).float()\n",
    "    nn_output_tensor = torch.from_numpy(nn_output).float()\n",
    "    \n",
    "    # Appending the tensors to a list\n",
    "    nn_input_final.append(nn_input_tensor)\n",
    "    nn_output_final.append(nn_output_tensor)\n",
    "    \n",
    "\n",
    "# Concatenate the neural network input and outputs from each rho values\n",
    "nn_in = torch.cat(nn_input_final)\n",
    "nn_out = torch.cat(nn_output_final)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(30):\n",
    "    optimizer.zero_grad()\n",
    "    reservoir_state = torch.zeros(nn_in.size(0), model.reservoir_size)\n",
    "    outputs, _ = model(nn_in, reservoir_state)\n",
    "    loss = criterion(outputs, nn_out)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, loss={loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4007b2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least squares error of test data: 43.1268310546875\n"
     ]
    }
   ],
   "source": [
    "nn_input_test_final = []\n",
    "nn_output_test_final = []\n",
    "\n",
    "# Test the network with given test rho values\n",
    "for rho in rho_values_test:\n",
    "    \n",
    "    # Define the Lorenz equation\n",
    "    def lorenz_deriv(x_y_z, t0, sigma=sigma, beta=beta, rho=rho):\n",
    "        x, y, z = x_y_z\n",
    "        return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]\n",
    "\n",
    "    np.random.seed(123)\n",
    "    x0 = -15 + 30 * np.random.random((100, 3))\n",
    "\n",
    "    x_t = np.asarray([integrate.odeint(lorenz_deriv, x0_j, t)\n",
    "                      for x0_j in x0])\n",
    "    \n",
    "    for j in range(100):\n",
    "        nn_input[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,:-1,:]\n",
    "        nn_output[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,1:,:]\n",
    "        \n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    nn_in_test_tensor = torch.from_numpy(nn_input).float()\n",
    "    nn_out_test_tensor = torch.from_numpy(nn_output).float()\n",
    "    \n",
    "    # Appending the tensors to a list\n",
    "    nn_input_test_final.append(nn_in_test_tensor)\n",
    "    nn_output_test_final.append(nn_out_test_tensor)\n",
    "    \n",
    "# Concatenate the neural network input and outputs from each rho values\n",
    "nn_in_test = torch.cat(nn_input_test_final)\n",
    "nn_out_test = torch.cat(nn_output_test_final)\n",
    "    \n",
    "# Test the network\n",
    "reservoir_state = torch.zeros(nn_in_test.size(0), model.reservoir_size)\n",
    "with torch.no_grad():\n",
    "    outputs, _ = model(nn_in_test, reservoir_state)\n",
    "    compute_mse = criterion(outputs, nn_out_test)\n",
    "\n",
    "    print('Least squares error of test data: {}'.format(compute_mse.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eef4e62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
