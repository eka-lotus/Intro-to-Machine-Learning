{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "359a2d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lenovo/opt/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/Lenovo/opt/anaconda3/lib/python3.9/site-packages/torchvision/image.so, 6): Library not loaded: @rpath/libpng16.16.dylib\n",
      "  Referenced from: /Users/Lenovo/opt/anaconda3/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Reason: Incompatible library version: image.so requires version 56.0.0 or later, but libpng16.16.dylib provides version 54.0.0'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Github link: https://github.com/sreksoz/Intro-to-Machine-Learning/tree/HW-4--Feed-Forward-Neural-Network\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d5e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 15)\n",
    "        self.fc2 = nn.Linear(15, 6)\n",
    "        self.fc3 = nn.Linear(6, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b38979f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "X = np.arange(0,31).reshape(-1,1)\n",
    "y = np.array([30,35,33,32,34,37,39,38,36,36,37,39,42,45,45,41,40,39,42,44,47,49,50,49,46,48,50,53,55,54,53])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89a3ffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the network and define the loss function and optimizer\n",
    "net = Net()\n",
    "criterion = nn.MSELoss()  # Mean Squared Error\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a272b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training (first 20) and test data \n",
    "X_train = X[:20].astype(np.float32)\n",
    "y_train = y[:20].astype(np.float32)\n",
    "X_test = X[20:].astype(np.float32)\n",
    "y_test = y[20:].astype(np.float32)\n",
    "\n",
    "# Convert the datasets into tensor form\n",
    "X_train_tensor = torch.from_numpy(X_train)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "X_test_tensor = torch.from_numpy(X_test)\n",
    "y_test_tensor = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "131fc227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1610.1602\n",
      "Epoch [2/100], Loss: 681.7791\n",
      "Epoch [3/100], Loss: 75266328.0000\n",
      "Epoch [4/100], Loss: 34360.2617\n",
      "Epoch [5/100], Loss: 32982.3438\n",
      "Epoch [6/100], Loss: 30336.8047\n",
      "Epoch [7/100], Loss: 6182.6152\n",
      "Epoch [8/100], Loss: 265077.7500\n",
      "Epoch [9/100], Loss: 33588.2969\n",
      "Epoch [10/100], Loss: 32258.8750\n",
      "Epoch [11/100], Loss: 30982.0996\n",
      "Epoch [12/100], Loss: 29755.8809\n",
      "Epoch [13/100], Loss: 28578.2246\n",
      "Epoch [14/100], Loss: 27447.1992\n",
      "Epoch [15/100], Loss: 26360.9648\n",
      "Epoch [16/100], Loss: 25317.7500\n",
      "Epoch [17/100], Loss: 24315.8398\n",
      "Epoch [18/100], Loss: 23353.6094\n",
      "Epoch [19/100], Loss: 22429.4824\n",
      "Epoch [20/100], Loss: 21541.9531\n",
      "Epoch [21/100], Loss: 20689.5684\n",
      "Epoch [22/100], Loss: 19870.9355\n",
      "Epoch [23/100], Loss: 19084.7246\n",
      "Epoch [24/100], Loss: 18329.6426\n",
      "Epoch [25/100], Loss: 17604.4648\n",
      "Epoch [26/100], Loss: 16908.0059\n",
      "Epoch [27/100], Loss: 16239.1221\n",
      "Epoch [28/100], Loss: 15596.7266\n",
      "Epoch [29/100], Loss: 14979.7725\n",
      "Epoch [30/100], Loss: 14387.2500\n",
      "Epoch [31/100], Loss: 13818.1904\n",
      "Epoch [32/100], Loss: 13271.6660\n",
      "Epoch [33/100], Loss: 12746.7852\n",
      "Epoch [34/100], Loss: 12242.6865\n",
      "Epoch [35/100], Loss: 11758.5527\n",
      "Epoch [36/100], Loss: 11293.5898\n",
      "Epoch [37/100], Loss: 10847.0371\n",
      "Epoch [38/100], Loss: 10418.1719\n",
      "Epoch [39/100], Loss: 10006.2871\n",
      "Epoch [40/100], Loss: 9610.7139\n",
      "Epoch [41/100], Loss: 9230.8047\n",
      "Epoch [42/100], Loss: 8865.9414\n",
      "Epoch [43/100], Loss: 8515.5254\n",
      "Epoch [44/100], Loss: 8178.9863\n",
      "Epoch [45/100], Loss: 7855.7739\n",
      "Epoch [46/100], Loss: 7545.3599\n",
      "Epoch [47/100], Loss: 7247.2388\n",
      "Epoch [48/100], Loss: 6960.9243\n",
      "Epoch [49/100], Loss: 6685.9473\n",
      "Epoch [50/100], Loss: 6421.8599\n",
      "Epoch [51/100], Loss: 6168.2295\n",
      "Epoch [52/100], Loss: 5924.6436\n",
      "Epoch [53/100], Loss: 5690.7026\n",
      "Epoch [54/100], Loss: 5466.0273\n",
      "Epoch [55/100], Loss: 5250.2480\n",
      "Epoch [56/100], Loss: 5043.0142\n",
      "Epoch [57/100], Loss: 4843.9863\n",
      "Epoch [58/100], Loss: 4652.8403\n",
      "Epoch [59/100], Loss: 4469.2627\n",
      "Epoch [60/100], Loss: 4292.9561\n",
      "Epoch [61/100], Loss: 4123.6309\n",
      "Epoch [62/100], Loss: 3961.0103\n",
      "Epoch [63/100], Loss: 3804.8306\n",
      "Epoch [64/100], Loss: 3654.8345\n",
      "Epoch [65/100], Loss: 3510.7781\n",
      "Epoch [66/100], Loss: 3372.4272\n",
      "Epoch [67/100], Loss: 3239.5547\n",
      "Epoch [68/100], Loss: 3111.9441\n",
      "Epoch [69/100], Loss: 2989.3862\n",
      "Epoch [70/100], Loss: 2871.6829\n",
      "Epoch [71/100], Loss: 2758.6396\n",
      "Epoch [72/100], Loss: 2650.0728\n",
      "Epoch [73/100], Loss: 2545.8057\n",
      "Epoch [74/100], Loss: 2445.6675\n",
      "Epoch [75/100], Loss: 2349.4944\n",
      "Epoch [76/100], Loss: 2257.1301\n",
      "Epoch [77/100], Loss: 2168.4233\n",
      "Epoch [78/100], Loss: 2083.2292\n",
      "Epoch [79/100], Loss: 2001.4094\n",
      "Epoch [80/100], Loss: 1922.8289\n",
      "Epoch [81/100], Loss: 1847.3608\n",
      "Epoch [82/100], Loss: 1774.8806\n",
      "Epoch [83/100], Loss: 1705.2710\n",
      "Epoch [84/100], Loss: 1638.4178\n",
      "Epoch [85/100], Loss: 1574.2120\n",
      "Epoch [86/100], Loss: 1512.5487\n",
      "Epoch [87/100], Loss: 1453.3275\n",
      "Epoch [88/100], Loss: 1396.4510\n",
      "Epoch [89/100], Loss: 1341.8271\n",
      "Epoch [90/100], Loss: 1289.3666\n",
      "Epoch [91/100], Loss: 1238.9834\n",
      "Epoch [92/100], Loss: 1190.5950\n",
      "Epoch [93/100], Loss: 1144.1232\n",
      "Epoch [94/100], Loss: 1099.4915\n",
      "Epoch [95/100], Loss: 1056.6272\n",
      "Epoch [96/100], Loss: 1015.4603\n",
      "Epoch [97/100], Loss: 975.9236\n",
      "Epoch [98/100], Loss: 937.9526\n",
      "Epoch [99/100], Loss: 901.4852\n",
      "Epoch [100/100], Loss: 866.4621\n",
      "Least squares error of 10 test data: 1666.5953369140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lenovo/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/Lenovo/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([11])) that is different to the input size (torch.Size([11, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()    # zero the gradients\n",
    "    outputs = net(X_train_tensor)    # forward pass \n",
    "    loss = criterion(outputs, y_train_tensor)   # compute the loss\n",
    "    loss.backward()   # backward pass\n",
    "    optimizer.step()   # update the weights\n",
    "        \n",
    "    \n",
    "    print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "# Test the network\n",
    "with torch.no_grad():\n",
    "    outputs = net(X_test_tensor)\n",
    "    compute_mse = criterion(outputs, y_test_tensor)\n",
    "        \n",
    "    print('Least squares error of 10 test data: {}'.format(compute_mse.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "159a8966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training (10 first and 10 last) and test data\n",
    "X_train2 = np.concatenate((X[:10], X[21:])).astype(np.float32)\n",
    "y_train2 = np.concatenate((y[:10], y[21:])).astype(np.float32)\n",
    "X_test2 = X[10:21].astype(np.float32)\n",
    "y_test2 = y[10:21].astype(np.float32)\n",
    "\n",
    "# Convert the datasets into tensor form\n",
    "X_train2_tensor = torch.from_numpy(X_train2)\n",
    "y_train2_tensor = torch.from_numpy(y_train2)\n",
    "X_test2_tensor = torch.from_numpy(X_test2)\n",
    "y_test2_tensor = torch.from_numpy(y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00bb12f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1171.9387\n",
      "Epoch [2/100], Loss: 1128.2594\n",
      "Epoch [3/100], Loss: 1086.3101\n",
      "Epoch [4/100], Loss: 1046.0216\n",
      "Epoch [5/100], Loss: 1007.3286\n",
      "Epoch [6/100], Loss: 970.1678\n",
      "Epoch [7/100], Loss: 934.4788\n",
      "Epoch [8/100], Loss: 900.2031\n",
      "Epoch [9/100], Loss: 867.2845\n",
      "Epoch [10/100], Loss: 835.6696\n",
      "Epoch [11/100], Loss: 805.3066\n",
      "Epoch [12/100], Loss: 776.1458\n",
      "Epoch [13/100], Loss: 748.1400\n",
      "Epoch [14/100], Loss: 721.2432\n",
      "Epoch [15/100], Loss: 695.4116\n",
      "Epoch [16/100], Loss: 670.6027\n",
      "Epoch [17/100], Loss: 646.7764\n",
      "Epoch [18/100], Loss: 623.8936\n",
      "Epoch [19/100], Loss: 601.9169\n",
      "Epoch [20/100], Loss: 580.8105\n",
      "Epoch [21/100], Loss: 560.5399\n",
      "Epoch [22/100], Loss: 541.0720\n",
      "Epoch [23/100], Loss: 522.3751\n",
      "Epoch [24/100], Loss: 504.4186\n",
      "Epoch [25/100], Loss: 487.1732\n",
      "Epoch [26/100], Loss: 470.6106\n",
      "Epoch [27/100], Loss: 454.7040\n",
      "Epoch [28/100], Loss: 439.4272\n",
      "Epoch [29/100], Loss: 424.7555\n",
      "Epoch [30/100], Loss: 410.6646\n",
      "Epoch [31/100], Loss: 397.1319\n",
      "Epoch [32/100], Loss: 384.1350\n",
      "Epoch [33/100], Loss: 371.6527\n",
      "Epoch [34/100], Loss: 359.6649\n",
      "Epoch [35/100], Loss: 348.1516\n",
      "Epoch [36/100], Loss: 337.0944\n",
      "Epoch [37/100], Loss: 326.4749\n",
      "Epoch [38/100], Loss: 316.2761\n",
      "Epoch [39/100], Loss: 306.4810\n",
      "Epoch [40/100], Loss: 297.0739\n",
      "Epoch [41/100], Loss: 288.0393\n",
      "Epoch [42/100], Loss: 279.3625\n",
      "Epoch [43/100], Loss: 271.0293\n",
      "Epoch [44/100], Loss: 263.0261\n",
      "Epoch [45/100], Loss: 255.3398\n",
      "Epoch [46/100], Loss: 247.9579\n",
      "Epoch [47/100], Loss: 240.8682\n",
      "Epoch [48/100], Loss: 234.0594\n",
      "Epoch [49/100], Loss: 227.5201\n",
      "Epoch [50/100], Loss: 221.2398\n",
      "Epoch [51/100], Loss: 215.2083\n",
      "Epoch [52/100], Loss: 209.4156\n",
      "Epoch [53/100], Loss: 203.8522\n",
      "Epoch [54/100], Loss: 198.5092\n",
      "Epoch [55/100], Loss: 193.3777\n",
      "Epoch [56/100], Loss: 188.4495\n",
      "Epoch [57/100], Loss: 183.7164\n",
      "Epoch [58/100], Loss: 179.1708\n",
      "Epoch [59/100], Loss: 174.8051\n",
      "Epoch [60/100], Loss: 170.6124\n",
      "Epoch [61/100], Loss: 166.5856\n",
      "Epoch [62/100], Loss: 162.7184\n",
      "Epoch [63/100], Loss: 159.0043\n",
      "Epoch [64/100], Loss: 155.4372\n",
      "Epoch [65/100], Loss: 152.0114\n",
      "Epoch [66/100], Loss: 148.7213\n",
      "Epoch [67/100], Loss: 145.5615\n",
      "Epoch [68/100], Loss: 142.5268\n",
      "Epoch [69/100], Loss: 139.6122\n",
      "Epoch [70/100], Loss: 136.8131\n",
      "Epoch [71/100], Loss: 134.1248\n",
      "Epoch [72/100], Loss: 131.5430\n",
      "Epoch [73/100], Loss: 129.0634\n",
      "Epoch [74/100], Loss: 126.6820\n",
      "Epoch [75/100], Loss: 124.3949\n",
      "Epoch [76/100], Loss: 122.1984\n",
      "Epoch [77/100], Loss: 120.0889\n",
      "Epoch [78/100], Loss: 118.0629\n",
      "Epoch [79/100], Loss: 116.1171\n",
      "Epoch [80/100], Loss: 114.2484\n",
      "Epoch [81/100], Loss: 112.4537\n",
      "Epoch [82/100], Loss: 110.7301\n",
      "Epoch [83/100], Loss: 109.0747\n",
      "Epoch [84/100], Loss: 107.4848\n",
      "Epoch [85/100], Loss: 105.9580\n",
      "Epoch [86/100], Loss: 104.4916\n",
      "Epoch [87/100], Loss: 103.0833\n",
      "Epoch [88/100], Loss: 101.7307\n",
      "Epoch [89/100], Loss: 100.4317\n",
      "Epoch [90/100], Loss: 99.1841\n",
      "Epoch [91/100], Loss: 97.9859\n",
      "Epoch [92/100], Loss: 96.8352\n",
      "Epoch [93/100], Loss: 95.7301\n",
      "Epoch [94/100], Loss: 94.6687\n",
      "Epoch [95/100], Loss: 93.6494\n",
      "Epoch [96/100], Loss: 92.6704\n",
      "Epoch [97/100], Loss: 91.7302\n",
      "Epoch [98/100], Loss: 90.8272\n",
      "Epoch [99/100], Loss: 89.9599\n",
      "Epoch [100/100], Loss: 89.1271\n",
      "Least squares error of 10 test data: 20.624591827392578\n"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()    # zero the gradients\n",
    "    outputs = net(X_train2_tensor)    # forward pass \n",
    "    loss = criterion(outputs, y_train2_tensor)   # compute the loss\n",
    "    loss.backward()   # backward pass\n",
    "    optimizer.step()   # update the weights\n",
    "        \n",
    "    \n",
    "    print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "# Test the network\n",
    "with torch.no_grad():\n",
    "    outputs = net(X_test2_tensor)\n",
    "    compute_mse = criterion(outputs, y_test2_tensor)\n",
    "        \n",
    "    print('Least squares error of 10 test data: {}'.format(compute_mse.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d761659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset and apply transformations\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# Get the pixel values for all images in the dataset\n",
    "train_data = train_dataset.data.float()  # Converet to float data type\n",
    "train_labels = train_dataset.targets\n",
    "test_data = test_dataset.data.float()\n",
    "test_labels = test_dataset.targets\n",
    "\n",
    "# Reshape the 2D images into 1D vectors\n",
    "X_train = X_train.view(X_train.size(0), -1)\n",
    "X_test = X_test.view(X_test.size(0), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3063fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA on the first 20 modes\n",
    "pca = PCA(n_components=20)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Convert numpy arrays back to tensors\n",
    "X_train_pca_tensor = torch.tensor(X_train_pca, dtype=torch.float32)\n",
    "X_test_pca_tensor = torch.tensor(X_test_pca, dtype=torch.float32)\n",
    "\n",
    "# Create dataloaders for the training and test data\n",
    "train_data = torch.utils.data.TensorDataset(X_train_pca_tensor, y_train)\n",
    "test_data = torch.utils.data.TensorDataset(X_test_pca_tensor, y_test)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e571ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/938], Loss: 0.8529\n",
      "Epoch [1/10], Step [200/938], Loss: 0.2340\n",
      "Epoch [1/10], Step [300/938], Loss: 0.3639\n",
      "Epoch [1/10], Step [400/938], Loss: 0.3721\n",
      "Epoch [1/10], Step [500/938], Loss: 0.3439\n",
      "Epoch [1/10], Step [600/938], Loss: 0.0986\n",
      "Epoch [1/10], Step [700/938], Loss: 0.5809\n",
      "Epoch [1/10], Step [800/938], Loss: 0.2960\n",
      "Epoch [1/10], Step [900/938], Loss: 0.0224\n",
      "Epoch [2/10], Step [100/938], Loss: 0.0678\n",
      "Epoch [2/10], Step [200/938], Loss: 0.0504\n",
      "Epoch [2/10], Step [300/938], Loss: 0.2456\n",
      "Epoch [2/10], Step [400/938], Loss: 0.1834\n",
      "Epoch [2/10], Step [500/938], Loss: 0.2388\n",
      "Epoch [2/10], Step [600/938], Loss: 0.1381\n",
      "Epoch [2/10], Step [700/938], Loss: 0.0747\n",
      "Epoch [2/10], Step [800/938], Loss: 0.1375\n",
      "Epoch [2/10], Step [900/938], Loss: 0.1992\n",
      "Epoch [3/10], Step [100/938], Loss: 0.0265\n",
      "Epoch [3/10], Step [200/938], Loss: 0.0670\n",
      "Epoch [3/10], Step [300/938], Loss: 0.2788\n",
      "Epoch [3/10], Step [400/938], Loss: 0.3408\n",
      "Epoch [3/10], Step [500/938], Loss: 0.0744\n",
      "Epoch [3/10], Step [600/938], Loss: 0.0892\n",
      "Epoch [3/10], Step [700/938], Loss: 0.0823\n",
      "Epoch [3/10], Step [800/938], Loss: 0.0854\n",
      "Epoch [3/10], Step [900/938], Loss: 0.2116\n",
      "Epoch [4/10], Step [100/938], Loss: 0.0635\n",
      "Epoch [4/10], Step [200/938], Loss: 0.0593\n",
      "Epoch [4/10], Step [300/938], Loss: 0.1006\n",
      "Epoch [4/10], Step [400/938], Loss: 0.0573\n",
      "Epoch [4/10], Step [500/938], Loss: 0.0820\n",
      "Epoch [4/10], Step [600/938], Loss: 0.0670\n",
      "Epoch [4/10], Step [700/938], Loss: 0.1946\n",
      "Epoch [4/10], Step [800/938], Loss: 0.0387\n",
      "Epoch [4/10], Step [900/938], Loss: 0.0313\n",
      "Epoch [5/10], Step [100/938], Loss: 0.4506\n",
      "Epoch [5/10], Step [200/938], Loss: 0.0501\n",
      "Epoch [5/10], Step [300/938], Loss: 0.0795\n",
      "Epoch [5/10], Step [400/938], Loss: 0.1058\n",
      "Epoch [5/10], Step [500/938], Loss: 0.1279\n",
      "Epoch [5/10], Step [600/938], Loss: 0.0262\n",
      "Epoch [5/10], Step [700/938], Loss: 0.0265\n",
      "Epoch [5/10], Step [800/938], Loss: 0.0598\n",
      "Epoch [5/10], Step [900/938], Loss: 0.0259\n",
      "Epoch [6/10], Step [100/938], Loss: 0.1231\n",
      "Epoch [6/10], Step [200/938], Loss: 0.1939\n",
      "Epoch [6/10], Step [300/938], Loss: 0.0689\n",
      "Epoch [6/10], Step [400/938], Loss: 0.1602\n",
      "Epoch [6/10], Step [500/938], Loss: 0.0314\n",
      "Epoch [6/10], Step [600/938], Loss: 0.2062\n",
      "Epoch [6/10], Step [700/938], Loss: 0.1859\n",
      "Epoch [6/10], Step [800/938], Loss: 0.0437\n",
      "Epoch [6/10], Step [900/938], Loss: 0.0069\n",
      "Epoch [7/10], Step [100/938], Loss: 0.2622\n",
      "Epoch [7/10], Step [200/938], Loss: 0.0538\n",
      "Epoch [7/10], Step [300/938], Loss: 0.0501\n",
      "Epoch [7/10], Step [400/938], Loss: 0.1706\n",
      "Epoch [7/10], Step [500/938], Loss: 0.0813\n",
      "Epoch [7/10], Step [600/938], Loss: 0.1114\n",
      "Epoch [7/10], Step [700/938], Loss: 0.1784\n",
      "Epoch [7/10], Step [800/938], Loss: 0.1268\n",
      "Epoch [7/10], Step [900/938], Loss: 0.0439\n",
      "Epoch [8/10], Step [100/938], Loss: 0.0605\n",
      "Epoch [8/10], Step [200/938], Loss: 0.0287\n",
      "Epoch [8/10], Step [300/938], Loss: 0.1061\n",
      "Epoch [8/10], Step [400/938], Loss: 0.0750\n",
      "Epoch [8/10], Step [500/938], Loss: 0.0087\n",
      "Epoch [8/10], Step [600/938], Loss: 0.0213\n",
      "Epoch [8/10], Step [700/938], Loss: 0.2077\n",
      "Epoch [8/10], Step [800/938], Loss: 0.0848\n",
      "Epoch [8/10], Step [900/938], Loss: 0.0781\n",
      "Epoch [9/10], Step [100/938], Loss: 0.1497\n",
      "Epoch [9/10], Step [200/938], Loss: 0.0061\n",
      "Epoch [9/10], Step [300/938], Loss: 0.0328\n",
      "Epoch [9/10], Step [400/938], Loss: 0.1381\n",
      "Epoch [9/10], Step [500/938], Loss: 0.0118\n",
      "Epoch [9/10], Step [600/938], Loss: 0.0502\n",
      "Epoch [9/10], Step [700/938], Loss: 0.2092\n",
      "Epoch [9/10], Step [800/938], Loss: 0.0244\n",
      "Epoch [9/10], Step [900/938], Loss: 0.0357\n",
      "Epoch [10/10], Step [100/938], Loss: 0.0245\n",
      "Epoch [10/10], Step [200/938], Loss: 0.0225\n",
      "Epoch [10/10], Step [300/938], Loss: 0.0911\n",
      "Epoch [10/10], Step [400/938], Loss: 0.1640\n",
      "Epoch [10/10], Step [500/938], Loss: 0.1862\n",
      "Epoch [10/10], Step [600/938], Loss: 0.0261\n",
      "Epoch [10/10], Step [700/938], Loss: 0.0091\n",
      "Epoch [10/10], Step [800/938], Loss: 0.0639\n",
      "Epoch [10/10], Step [900/938], Loss: 0.0903\n",
      "Accuracy of the network on the 10000 test images: 96.1 %\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# Train the network\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
    "\n",
    "# Test the network\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f75d6995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/938], Loss: 0.6161\n",
      "Epoch [1/5], Step [200/938], Loss: 0.4498\n",
      "Epoch [1/5], Step [300/938], Loss: 0.2798\n",
      "Epoch [1/5], Step [400/938], Loss: 0.1470\n",
      "Epoch [1/5], Step [500/938], Loss: 0.1936\n",
      "Epoch [1/5], Step [600/938], Loss: 0.0931\n",
      "Epoch [1/5], Step [700/938], Loss: 0.0931\n",
      "Epoch [1/5], Step [800/938], Loss: 0.1285\n",
      "Epoch [1/5], Step [900/938], Loss: 0.1857\n",
      "Epoch [2/5], Step [100/938], Loss: 0.0749\n",
      "Epoch [2/5], Step [200/938], Loss: 0.0305\n",
      "Epoch [2/5], Step [300/938], Loss: 0.0520\n",
      "Epoch [2/5], Step [400/938], Loss: 0.2020\n",
      "Epoch [2/5], Step [500/938], Loss: 0.0580\n",
      "Epoch [2/5], Step [600/938], Loss: 0.1080\n",
      "Epoch [2/5], Step [700/938], Loss: 0.1179\n",
      "Epoch [2/5], Step [800/938], Loss: 0.0751\n",
      "Epoch [2/5], Step [900/938], Loss: 0.0350\n",
      "Epoch [3/5], Step [100/938], Loss: 0.0575\n",
      "Epoch [3/5], Step [200/938], Loss: 0.1940\n",
      "Epoch [3/5], Step [300/938], Loss: 0.0537\n",
      "Epoch [3/5], Step [400/938], Loss: 0.0807\n",
      "Epoch [3/5], Step [500/938], Loss: 0.0046\n",
      "Epoch [3/5], Step [600/938], Loss: 0.1250\n",
      "Epoch [3/5], Step [700/938], Loss: 0.1057\n",
      "Epoch [3/5], Step [800/938], Loss: 0.0298\n",
      "Epoch [3/5], Step [900/938], Loss: 0.1192\n",
      "Epoch [4/5], Step [100/938], Loss: 0.3393\n",
      "Epoch [4/5], Step [200/938], Loss: 0.1787\n",
      "Epoch [4/5], Step [300/938], Loss: 0.0685\n",
      "Epoch [4/5], Step [400/938], Loss: 0.2053\n",
      "Epoch [4/5], Step [500/938], Loss: 0.1123\n",
      "Epoch [4/5], Step [600/938], Loss: 0.0189\n",
      "Epoch [4/5], Step [700/938], Loss: 0.0622\n",
      "Epoch [4/5], Step [800/938], Loss: 0.1765\n",
      "Epoch [4/5], Step [900/938], Loss: 0.1326\n",
      "Epoch [5/5], Step [100/938], Loss: 0.0069\n",
      "Epoch [5/5], Step [200/938], Loss: 0.0152\n",
      "Epoch [5/5], Step [300/938], Loss: 0.0719\n",
      "Epoch [5/5], Step [400/938], Loss: 0.0764\n",
      "Epoch [5/5], Step [500/938], Loss: 0.0077\n",
      "Epoch [5/5], Step [600/938], Loss: 0.0200\n",
      "Epoch [5/5], Step [700/938], Loss: 0.0106\n",
      "Epoch [5/5], Step [800/938], Loss: 0.0935\n",
      "Epoch [5/5], Step [900/938], Loss: 0.0302\n",
      "Test Accuracy of the model on the 10000 test images: 98.05 %\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM network architecture\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 28\n",
    "sequence_length = 28\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 10\n",
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = LSTMNet(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa607b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset from OpenML\n",
    "mnist = fetch_openml('mnist_784')\n",
    "\n",
    "# Convert the data and labels to numpy arrays\n",
    "X = mnist.data.astype('float32') / 255.0    \n",
    "y = mnist.target.astype('int32')\n",
    "\n",
    "# Perform PCA to reduce the dimensionality of the data\n",
    "pca = PCA(n_components=20)\n",
    "X_pca_train = pca.fit_transform(X)\n",
    "\n",
    "# Split the whole dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca_train, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a20d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9058571428571428\n"
     ]
    }
   ],
   "source": [
    "# Train an SVM classifier on the training set\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bea7cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7943571428571429\n"
     ]
    }
   ],
   "source": [
    "# Train a decision tree classifier on the training set\n",
    "clf = DecisionTreeClassifier(max_depth=10)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05656f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
